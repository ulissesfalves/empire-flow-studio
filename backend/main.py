import os
import json
import re
import time
import asyncio
import subprocess
import multiprocessing
from datetime import datetime
from typing import AsyncGenerator
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import edge_tts
import requests
from duckduckgo_search import DDGS
import PIL.Image
import numpy as np
import whisper
from moviepy.config import change_settings
from moviepy.editor import *
from dotenv import load_dotenv
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont
from fpdf import FPDF
import random

# ==========================================
# OTIMIZA√á√ÉO #7: CONFIGURA√á√ïES GLOBAIS
# ==========================================

# Limitar threads do NumPy/OpenCV (evita sobrecarga)
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"

# Configura√ß√µes do Whisper
os.environ["WHISPER_CPP_THREADS"] = str(max(1, multiprocessing.cpu_count() - 1))

# Garbage Collector menos agressivo
import gc
gc.set_threshold(700, 10, 10)

# Prioridade baixa para FFmpeg no Windows
if os.name == 'nt':
    original_subprocess_run = subprocess.run
    def run_with_low_priority(*args, **kwargs):
        if 'creationflags' not in kwargs:
            kwargs['creationflags'] = subprocess.BELOW_NORMAL_PRIORITY_CLASS
        return original_subprocess_run(*args, **kwargs)
    subprocess.run = run_with_low_priority

# Cache de transforma√ß√µes PIL
Image.MAX_IMAGE_PIXELS = None

# ==========================================
# PERFIS DE PERFORMANCE
# ==========================================

PERFORMANCE_PROFILES = {
    "ultra_low": {
        "description": "M√°ximo desempenho, qualidade m√≠nima",
        "resolution": (854, 480),
        "fps": 20,
        "preset": "ultrafast",
        "bitrate": "800k",
        "crf": "28",
        "threads": 1,
        "whisper_model": "tiny",
        "enable_subtitles": False,
    },
    "low": {
        "description": "Hardware modesto (padr√£o recomendado)",
        "resolution": (1280, 720),
        "fps": 24,
        "preset": "veryfast",
        "bitrate": "1500k",
        "crf": "25",
        "threads": max(1, multiprocessing.cpu_count() // 2),
        "whisper_model": "tiny",
        "enable_subtitles": True,
    },
    "balanced": {
        "description": "Balanceado (CPUs 4+ n√∫cleos)",
        "resolution": (1280, 720),
        "fps": 30,
        "preset": "fast",
        "bitrate": "2500k",
        "crf": "23",
        "threads": max(2, multiprocessing.cpu_count() - 1),
        "whisper_model": "base",
        "enable_subtitles": True,
    },
    "quality": {
        "description": "M√°xima qualidade (hardware potente)",
        "resolution": (1920, 1080),
        "fps": 30,
        "preset": "medium",
        "bitrate": "5000k",
        "crf": "20",
        "threads": multiprocessing.cpu_count() - 1,
        "whisper_model": "base",
        "enable_subtitles": True,
    }
}

# ==========================================
# FORMATOS DE ASPECT RATIO
# ==========================================

ASPECT_RATIOS = {
    "vertical": {
        "name": "Vertical (Shorts/TikTok/Reels)",
        "ratio": "9:16",
        "resolutions": {
            "ultra_low": (480, 854),
            "low": (720, 1280),
            "balanced": (720, 1280),
            "quality": (1080, 1920)
        }
    },
    "horizontal": {
        "name": "Horizontal (YouTube/TV)",
        "ratio": "16:9",
        "resolutions": {
            "ultra_low": (854, 480),
            "low": (1280, 720),
            "balanced": (1280, 720),
            "quality": (1920, 1080)
        }
    }
}

def detect_optimal_profile():
    """Detecta hardware e retorna perfil recomendado"""
    cpu_count = multiprocessing.cpu_count()
    
    try:
        import psutil
        ram_gb = psutil.virtual_memory().total / (1024**3)
    except:
        ram_gb = 4
    
    if cpu_count <= 2 or ram_gb < 4:
        return "ultra_low"
    elif cpu_count <= 4 or ram_gb < 8:
        return "low"
    elif cpu_count <= 8 or ram_gb < 16:
        return "balanced"
    else:
        return "quality"

CURRENT_PROFILE = os.getenv("PERFORMANCE_PROFILE", detect_optimal_profile())
SETTINGS = PERFORMANCE_PROFILES[CURRENT_PROFILE].copy()

# Aspect ratio padr√£o (ser√° sobrescrito via par√¢metro da API)
CURRENT_ASPECT_RATIO = "horizontal"

print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   PERFIL DE PERFORMANCE: {CURRENT_PROFILE.upper():^12}  ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë FPS: {SETTINGS['fps']}                              ‚ïë
‚ïë Preset: {SETTINGS['preset']:^10}                ‚ïë
‚ïë Threads: {SETTINGS['threads']}                            ‚ïë
‚ïë Legendas: {'‚úÖ Sim' if SETTINGS['enable_subtitles'] else '‚ùå N√£o':^5}                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""")

# --- CONFIGURA√á√ÉO ORIGINAL ---
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

caminho_magick = r"C:\Program Files\ImageMagick-7.1.2-Q16-HDRI\magick.exe"
if os.path.exists(caminho_magick):
    change_settings({"IMAGEMAGICK_BINARY": caminho_magick})

load_dotenv()

PROJECTS_DIR = "backend/projects"
os.makedirs(PROJECTS_DIR, exist_ok=True)

# --- CHAVES ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LUMA_API_KEY = os.getenv("LUMA_API_KEY")
REPLICATE_API_KEY = os.getenv("REPLICATE_API_KEY")  # ‚úÖ NOVO

# --- CONFIGURA√á√ïES DE GERA√á√ÉO DE IMAGENS ---
IMAGE_PROVIDERS = {
    "flux_pro": {
        "name": "Flux Pro (Replicate)",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
        "cost": "$0.055/img",
        "requires_api": True,
        "api_key_var": "REPLICATE_API_KEY",
        "supports_aspect_ratio": True,
        "supports_seed": True
    },
    "dalle3": {
        "name": "DALL-E 3 (OpenAI)",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê",
        "cost": "$0.040/img",
        "requires_api": True,
        "api_key_var": "OPENAI_API_KEY",
        "supports_aspect_ratio": False,
        "supports_seed": False
    },
    "sdxl": {
        "name": "Stable Diffusion XL (Replicate)",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê",
        "cost": "$0.0025/img",
        "requires_api": True,
        "api_key_var": "REPLICATE_API_KEY",
        "supports_aspect_ratio": True,
        "supports_seed": True
    },
    "banana": {
        "name": "Nano Banana (Replicate)",
        "quality": "‚≠ê‚≠ê‚≠ê",
        "cost": "$0.002/img",
        "requires_api": True,
        "api_key_var": "REPLICATE_API_KEY",
        "supports_aspect_ratio": True,
        "supports_seed": True
    },
    "pollinations": {
        "name": "Pollinations (Gratuito)",
        "quality": "‚≠ê‚≠ê",
        "cost": "Gr√°tis",
        "requires_api": False,
        "api_key_var": None,
        "supports_aspect_ratio": True,
        "supports_seed": False
    }
}

# Template de prompt universal para consist√™ncia visual
VISUAL_STYLE_TEMPLATES = {
    "documentary": """Cinematic documentary photography, 8k resolution, photorealistic, 
professional color grading, National Geographic quality, dramatic natural lighting, 
shallow depth of field, award-winning composition.

SUBJECT: {scene_description}

Style: Professional documentary, no text, no watermarks, highly detailed.""",
    
    "cinematic": """Hollywood cinematic shot, IMAX quality, 8k, photorealistic rendering,
professional cinematography, dramatic lighting, anamorphic lens, film grain,
color graded like a blockbuster movie.

SUBJECT: {scene_description}

Style: Cinematic masterpiece, no text, ultra detailed, epic composition.""",
    
    "photorealistic": """Ultra-realistic photography, 8k RAW, professional DSLR,
perfect exposure, natural lighting, Leica quality, hyperrealistic details,
National Geographic award winner.

SUBJECT: {scene_description}

Style: Photorealistic, no CGI, authentic, highly detailed."""
}

# --- CONFIGURA√á√ïES DE VOZ ---
VOICE_CONFIGS = {
    # OpenAI TTS Voices
    "openai_onyx": {
        "provider": "openai",
        "voice": "onyx",
        "name": "Onyx (Deep)",
        "description": "Voz masculina profunda e autorit√°ria"
    },
    "openai_alloy": {
        "provider": "openai",
        "voice": "alloy",
        "name": "Alloy (Neutral)",
        "description": "Voz neutra e vers√°til"
    },
    "openai_echo": {
        "provider": "openai",
        "voice": "echo",
        "name": "Echo (Soft)",
        "description": "Voz suave e calma"
    },
    "openai_nova": {
        "provider": "openai",
        "voice": "nova",
        "name": "Nova (Energetic)",
        "description": "Voz energ√©tica e jovem"
    },
    # ElevenLabs (usa ELEVENLABS_VOICE_ID do .env)
    "elevenlabs": {
        "provider": "elevenlabs",
        "voice": None,  # Usa ELEVENLABS_VOICE_ID
        "name": "ElevenLabs (Premium)",
        "description": "Voz configurada no .env"
    },
    # Edge TTS
    "edge_tts": {
        "provider": "edge",
        "voice": "en-US-ChristopherNeural",
        "name": "Edge TTS (Gratuito)",
        "description": "Voz gratuita da Microsoft"
    },
    # Gemini TTS (experimental)
    "gemini_tts": {
        "provider": "gemini",
        "voice": "en-US-Neural2-J",
        "name": "Gemini TTS",
        "description": "S√≠ntese de voz do Google AI"
    }
}

# Estilos de narra√ß√£o
VOICE_STYLES = {
    "hype": {
        "name": "Hype/Fast",
        "speed": 1.15,
        "pitch": "+5Hz",
        "instruction": "Speak with high energy, enthusiasm, and fast pacing. Perfect for viral content and hype moments."
    },
    "storyteller": {
        "name": "Storyteller",
        "speed": 1.0,
        "pitch": "0Hz",
        "instruction": "Speak like a captivating storyteller with varied tone, dramatic pauses, and emotional inflection."
    },
    "documentary": {
        "name": "Documentary",
        "speed": 0.95,
        "pitch": "-3Hz",
        "instruction": "Speak with authoritative clarity, measured pacing, and professional documentary tone."
    },
    "asmr": {
        "name": "ASMR/Calm",
        "speed": 0.85,
        "pitch": "-5Hz",
        "instruction": "Speak in a soft, soothing, calm whisper with gentle pacing and relaxing tone."
    },
    "authoritative": {
        "name": "Authoritative",
        "speed": 0.90,
        "pitch": "-8Hz",
        "instruction": "Speak with commanding authority, deep resonance, and confident assertiveness."
    }
}

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)
app.mount("/projects", StaticFiles(directory=PROJECTS_DIR), name="projects")

# --- MODELOS WHISPER ---
print(f"‚è≥ Carregando modelo Whisper ({SETTINGS['whisper_model']})...")
whisper_model = whisper.load_model(SETTINGS['whisper_model'])
print(f"‚úÖ Whisper {SETTINGS['whisper_model']} Carregado!")

# --- UTILIT√ÅRIOS ---
def clean_text_for_tts(text):
    if not text: return ""
    text = re.sub(r'(?i)(voiceover|narrator|speaker|tone|style)\s*[:\-]\s*', '', text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    text = re.sub(r'[\*#]', '', text)
    text = text.replace("'", "'").replace(""", '"').replace(""", '"')
    return text.strip()

async def send_log(msg: str):
    return f"data: {json.dumps({'log': msg})}\n\n"

# ==========================================
# OTIMIZA√á√ÉO #6: STITCH OTIMIZADO
# ==========================================

def stitch_video_files(video_files, output_path):
    """Vers√£o otimizada com stream copy garantido"""
    if not video_files:
        print("‚ùå Nenhum arquivo para concatenar")
        return False
    
    list_file = os.path.join(os.path.dirname(output_path), "files.txt")
    
    # Valida que todos os arquivos existem e diagn√≥stico
    valid_files = []
    print(f"\nüîç DIAGN√ìSTICO DE V√çDEOS INDIVIDUAIS:")
    for v in video_files:
        if os.path.exists(v):
            size = os.path.getsize(v)
            print(f"  ‚úÖ {os.path.basename(v)} - {size/1024:.1f}KB")
            
            # Testa se o v√≠deo √© v√°lido com ffprobe (timeout maior)
            try:
                probe_cmd = ["ffprobe", "-v", "error", "-show_entries", 
                           "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", v]
                result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
                duration = float(result.stdout.strip())
                print(f"     Dura√ß√£o: {duration:.2f}s")
                valid_files.append(v)
            except subprocess.TimeoutExpired:
                print(f"     ‚è±Ô∏è Timeout na verifica√ß√£o (mas arquivo existe, incluindo)")
                valid_files.append(v)
            except Exception as e:
                print(f"     ‚ö†Ô∏è Erro na verifica√ß√£o: {str(e)[:50]} (incluindo mesmo assim)")
                valid_files.append(v)  # Inclui mesmo com erro
        else:
            print(f"  ‚ùå AUSENTE: {os.path.basename(v)}")
    
    if not valid_files:
        print("‚ùå Nenhum arquivo v√°lido encontrado")
        return False
    
    print(f"\nüìù Criando lista de concatena√ß√£o com {len(valid_files)} v√≠deos...")
    with open(list_file, 'w', encoding='utf-8') as f:
        for v in valid_files:
            abs_path = os.path.abspath(v).replace('\\', '/')
            f.write(f"file '{abs_path}'\n")
    
    # Mostra conte√∫do do arquivo de lista
    with open(list_file, 'r', encoding='utf-8') as f:
        print(f"Conte√∫do de files.txt:\n{f.read()}")
    
    # PASSO 1: Tenta stream copy direto (R√ÅPIDO)
    print("\nüîÑ Tentando concatena√ß√£o com stream copy...")
    cmd_fast = [
        "ffmpeg", "-y", "-f", "concat", "-safe", "0",
        "-i", list_file,
        "-c", "copy",
        "-movflags", "+faststart",
        output_path
    ]
    
    try:
        result = subprocess.run(cmd_fast, check=True, capture_output=True, text=True)
        print("‚úÖ Stream copy SUCESSO")
        
        # Valida arquivo de sa√≠da
        if os.path.exists(output_path):
            size = os.path.getsize(output_path)
            print(f"   Arquivo final: {size/1024:.1f}KB")
            
            # Testa o arquivo final
            try:
                probe_cmd = ["ffprobe", "-v", "error", "-show_entries", 
                           "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", output_path]
                result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
                duration = float(result.stdout.strip())
                print(f"   Dura√ß√£o total: {duration:.2f}s")
            except subprocess.TimeoutExpired:
                print("   ‚è±Ô∏è Timeout na verifica√ß√£o (mas arquivo foi criado)")
            except:
                print("   ‚ö†Ô∏è N√£o foi poss√≠vel verificar dura√ß√£o (mas arquivo existe)")
        
        if os.path.exists(list_file):
            os.remove(list_file)
        return True
    
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è Stream copy FALHOU")
        print(f"STDERR: {e.stderr[:500]}")
        print("\nüîÑ Tentando re-encoding com codec compat√≠vel...")
        
        # PASSO 2: Fallback com re-encoding otimizado e compat√≠vel
        cmd_slow = [
            "ffmpeg", "-y", "-f", "concat", "-safe", "0",
            "-i", list_file,
            "-c:v", "libx264",
            "-preset", SETTINGS['preset'],
            "-crf", SETTINGS['crf'],
            "-pix_fmt", "yuv420p",
            "-profile:v", "baseline",  # M√°xima compatibilidade
            "-level", "3.0",
            "-movflags", "+faststart",
            "-c:a", "aac",
            "-b:a", "128k",
            "-ar", "44100",
            "-ac", "2",
            "-threads", str(SETTINGS['threads']),
            output_path
        ]
        
        try:
            result = subprocess.run(cmd_slow, check=True, capture_output=True, text=True)
            print("‚úÖ Re-encoding SUCESSO")
            
            # Valida arquivo de sa√≠da
            if os.path.exists(output_path):
                size = os.path.getsize(output_path)
                print(f"   Arquivo final: {size/1024:.1f}KB")
            
            return True
        except subprocess.CalledProcessError as e2:
            print(f"‚ùå Re-encoding FALHOU")
            print(f"STDERR: {e2.stderr[:500]}")
            return False
    
    finally:
        if os.path.exists(list_file):
            os.remove(list_file)

# --- LOGGER ---
class ProjectLogger:
    def __init__(self, project_path, topic, writer_config, critic_config, duration, voice_config, voice_style):
        self.filepath = os.path.join(project_path, "production_log.json")
        self.data = {
            "meta": {
                "project_id": os.path.basename(project_path),
                "topic": topic,
                "duration_mode": duration,
                "voice_config": voice_config,
                "voice_style": voice_style,
                "performance_profile": CURRENT_PROFILE,
                "agents": {"writer": writer_config, "critic": critic_config},
                "start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "status": "in_progress"
            },
            "timeline": []
        }
        self.save()

    def log_event(self, stage, status, details=None):
        entry = {
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "stage": stage,
            "status": status,
            "details": details or {}
        }
        self.data["timeline"].append(entry)
        self.save()

    def finish(self, status="completed", error=None):
        self.data["meta"]["end_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.data["meta"]["status"] = status
        if error: self.data["meta"]["error_msg"] = str(error)
        self.save()

    def save(self):
        with open(self.filepath, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, indent=4, ensure_ascii=False)

# --- PDF GENERATOR ---
class PDFGenerator:
    def safe_encode(self, text):
        clean = text.replace("'", "'").replace(""", '"').replace(""", '"').replace("‚Äì", "-")
        return clean.encode('latin-1', 'replace').decode('latin-1')

    def save_script(self, project_path, topic, script_data):
        pdf = FPDF()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        pdf.set_font("Arial", 'B', 16)
        pdf.cell(0, 10, txt=self.safe_encode(f"ROTEIRO VIRAL: {topic}"), ln=1, align='C')
        pdf.ln(10)

        for act in script_data:
            pdf.set_font("Arial", 'B', 14)
            pdf.set_text_color(0, 0, 0)
            pdf.cell(0, 10, txt=self.safe_encode(f"ATO: {act['title']}"), ln=1)
            pdf.ln(2)

            for i, scene in enumerate(act['scenes']):
                pdf.set_font("Arial", 'I', 10)
                pdf.set_text_color(100, 100, 100)
                visual_text = f"[Visual: {scene.get('visual_search_term', 'N/A')}]"
                pdf.multi_cell(0, 5, txt=self.safe_encode(visual_text))
                pdf.set_font("Arial", '', 12)
                pdf.set_text_color(0, 0, 0)
                narration_text = f"Narrador: {scene.get('narration', '')}"
                pdf.multi_cell(0, 8, txt=self.safe_encode(narration_text))
                pdf.ln(5)
            pdf.ln(5)

        filename = "roteiro_viral.pdf"
        full_path = os.path.join(project_path, filename)
        pdf.output(full_path)
        return filename

# --- SUBTITLE GENERATOR ---
class SubtitleGenerator:
    def get_font(self, size):
        fonts = ["arialbd.ttf", "ariblk.ttf", "SegoeUI-Bold.ttf", "impact.ttf", "DejaVuSans-Bold.ttf"]
        for name in fonts:
            try: return ImageFont.truetype(name, size)
            except: continue
        return ImageFont.load_default()

    def split_text_into_lines(self, words, font, max_width, draw, space_width_buffer):
        lines = []
        current_line = []
        current_w = 0
        space_w = draw.textlength(" ", font=font) + space_width_buffer

        for word_data in words:
            word = word_data['word'].strip()
            word_w = draw.textlength(word, font=font)
            if current_w + word_w <= max_width:
                current_line.append(word_data)
                current_w += word_w + space_w
            else:
                if current_line: lines.append(current_line)
                current_line = [word_data]
                current_w = word_w + space_w
        if current_line: lines.append(current_line)
        return lines

    def generate_karaoke(self, audio_path, video_w, video_h):
        try:
            # Transcri√ß√£o otimizada
            result = whisper_model.transcribe(
                audio_path,
                word_timestamps=True,
                language="en",
                beam_size=1,
                best_of=1,
                fp16=False,
                temperature=0.0
            )
            segments = result['segments']
        except Exception as e:
            print(f"Erro Whisper: {e}")
            return []

        subtitle_clips = []
        
        # Adapta tamanho da fonte baseado na altura do v√≠deo
        base_font_size = int(video_h * 0.055)  # Reduzido de 0.085 para melhor fit vertical
        pop_font_size = int(base_font_size * 1.25)
        
        # Margens adaptativas
        margin_x = int(video_w * 0.10)  # 10% nas laterais
        margin_y = int(video_h * 0.10)  # 10% superior e inferior
        
        max_text_width = video_w - (margin_x * 2)
        font_normal = self.get_font(base_font_size)
        font_large = self.get_font(pop_font_size)
        text_color = (255, 255, 255, 255)
        highlight_color = (255, 215, 0, 255)
        stroke_color = (0, 0, 0, 255)
        stroke_width = 6
        SPACE_BUFFER = 25

        for segment in segments:
            all_words = segment['words']
            if not all_words: continue
            dummy_img = Image.new('RGBA', (1, 1))
            dummy_draw = ImageDraw.Draw(dummy_img)
            lines = self.split_text_into_lines(all_words, font_normal, max_text_width, dummy_draw, SPACE_BUFFER)
            line_height = base_font_size * 1.6
            total_block_height = len(lines) * line_height
            
            # CORRE√á√ÉO: Posicionamento seguro com margens
            # Centraliza verticalmente com margem de seguran√ßa
            start_y = (video_h - total_block_height) / 2
            
            # Garante que n√£o ultrapasse os limites
            if start_y < margin_y:
                start_y = margin_y  # N√£o passa do topo
            if start_y + total_block_height > video_h - margin_y:
                start_y = video_h - margin_y - total_block_height  # N√£o passa do fundo
            
            flat_words = [w for line in lines for w in line]

            for i, active_word in enumerate(flat_words):
                start_t = active_word['start']
                end_t = active_word['end']
                img = Image.new('RGBA', (video_w, video_h), (0, 0, 0, 0))
                draw = ImageDraw.Draw(img)
                current_y = start_y
                word_global_index = 0

                for line in lines:
                    line_total_w = 0
                    normal_space_w = dummy_draw.textlength(" ", font=font_normal) + SPACE_BUFFER
                    words_in_line = [w['word'].strip() for w in line]
                    for w_str in words_in_line:
                        line_total_w += dummy_draw.textlength(w_str, font=font_normal)
                    if len(words_in_line) > 1:
                        line_total_w += (len(words_in_line) - 1) * normal_space_w
                    current_x = (video_w - line_total_w) / 2

                    for word_data in line:
                        word_txt = word_data['word'].strip()
                        if word_global_index > i:
                            w_len = dummy_draw.textlength(word_txt, font=font_normal)
                            current_x += w_len + normal_space_w
                            word_global_index += 1
                            continue

                        is_active = (word_global_index == i)
                        current_font = font_large if is_active else font_normal
                        current_color = highlight_color if is_active else text_color
                        normal_w = dummy_draw.textlength(word_txt, font=font_normal)
                        draw_x = current_x
                        draw_y = current_y

                        if is_active:
                            large_w = dummy_draw.textlength(word_txt, font=font_large)
                            offset_x = (large_w - normal_w) / 2
                            offset_y = (pop_font_size - base_font_size) / 1.3
                            draw_x = current_x - offset_x
                            draw_y = current_y - offset_y

                        for adj_x in range(-stroke_width, stroke_width+1):
                            for adj_y in range(-stroke_width, stroke_width+1):
                                if abs(adj_x) >= stroke_width-1 or abs(adj_y) >= stroke_width-1:
                                    draw.text((draw_x+adj_x, draw_y+adj_y), word_txt, font=current_font, fill=stroke_color)
                        draw.text((draw_x, draw_y), word_txt, font=current_font, fill=current_color)

                        current_x += normal_w + normal_space_w
                        word_global_index += 1
                    current_y += line_height

                img_np = np.array(img)
                txt_clip = ImageClip(img_np).set_start(start_t).set_end(end_t).set_duration(end_t - start_t)
                subtitle_clips.append(txt_clip)

        return subtitle_clips

# --- API WRAPPERS ---
def call_gemini_api(prompt_text, model, max_retries=3):
    if not GEMINI_API_KEY: return {"error": "Chave Gemini n√£o configurada"}
    url = f"https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {"contents": [{"parts": [{"text": prompt_text}]}], "generationConfig": {"temperature": 0.7}}
    
    for attempt in range(max_retries):
        try:
            r = requests.post(url, headers=headers, json=payload, timeout=120)
            
            if r.status_code == 429: 
                return {"error": "ERRO DE COTA (429): Limite do Gemini excedido."}
            
            if r.status_code != 200: 
                return {"error": f"Erro Gemini ({r.status_code}): {r.text}"}
            
            # Parse robusto da resposta
            response_data = r.json()
            
            # Verifica se h√° candidates
            if 'candidates' not in response_data or not response_data['candidates']:
                # Pode ser bloqueio de seguran√ßa
                if 'promptFeedback' in response_data:
                    feedback = response_data['promptFeedback']
                    block_reason = feedback.get('blockReason', 'UNKNOWN')
                    return {"error": f"Gemini bloqueou o conte√∫do: {block_reason}. Tente outro modelo ou prompt."}
                return {"error": f"Resposta vazia do Gemini. Response: {response_data}"}
            
            # Extrai o texto
            candidate = response_data['candidates'][0]
            
            if 'content' not in candidate:
                return {"error": f"Candidate sem 'content'. Data: {candidate}"}
            
            if 'parts' not in candidate['content']:
                return {"error": f"Content sem 'parts'. Data: {candidate['content']}"}
            
            if not candidate['content']['parts']:
                return {"error": "Parts vazio"}
            
            text = candidate['content']['parts'][0].get('text', '')
            
            if not text:
                return {"error": "Texto vazio na resposta"}
            
            return {"text": text}
        
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è Timeout no Gemini (tentativa {attempt+1}/{max_retries}). Retentando em 2s...")
                time.sleep(2)
                continue
            else:
                return {"error": f"TIMEOUT: Gemini n√£o respondeu ap√≥s {max_retries} tentativas (120s cada)."}
        
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è Erro de conex√£o Gemini (tentativa {attempt+1}/{max_retries}). Retentando...")
                time.sleep(2)
                continue
            else:
                return {"error": f"Erro de conex√£o: {str(e)}"}
        
        except KeyError as e:
            # Erro de parsing - mostra resposta completa para debug
            return {"error": f"Erro parsing Gemini (campo '{e}' ausente). Response: {r.text[:500]}"}
        
        except Exception as e: 
            return {"error": f"Erro inesperado: {str(e)}"}
    
    return {"error": "Falha ap√≥s todas as tentativas"}

def call_openai_api(prompt_text, model, max_retries=3):
    if not OPENAI_API_KEY: return {"error": "Chave OpenAI n√£o configurada"}
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model, 
                messages=[{"role": "user", "content": prompt_text}], 
                temperature=0.7,
                timeout=120  # Timeout de 120s
            )
            return {"text": response.choices[0].message.content}
        
        except Exception as e:
            error_str = str(e)
            
            if "429" in error_str or "quota" in error_str.lower():
                return {"error": "ERRO DE COTA (429): Limite da OpenAI excedido."}
            
            if "timeout" in error_str.lower() or "timed out" in error_str.lower():
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è Timeout na OpenAI (tentativa {attempt+1}/{max_retries}). Retentando em 2s...")
                    time.sleep(2)
                    continue
                else:
                    return {"error": f"TIMEOUT: OpenAI n√£o respondeu ap√≥s {max_retries} tentativas."}
            
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è Erro OpenAI (tentativa {attempt+1}/{max_retries}). Retentando...")
                time.sleep(2)
                continue
            
            return {"error": f"Erro OpenAI: {error_str}"}
    
    return {"error": "Falha ap√≥s todas as tentativas"}

async def generate_text(provider, model, prompt):
    if provider == "openai": return call_openai_api(prompt, model)
    return call_gemini_api(prompt, model)

# --- C√âREBRO VIRAL ---
class ViralBrain:
    def __init__(self, writer_provider, writer_model, critic_provider, critic_model, duration_instruction):
        self.writer_provider = writer_provider
        self.writer_model = writer_model
        self.critic_provider = critic_provider
        self.critic_model = critic_model
        self.duration_instruction = duration_instruction

    async def run_writer_critic_loop(self, topic, chapter_title, facts, logger):
        max_iterations = 3
        current_draft_json = None
        feedback = f"Focus on high retention. {self.duration_instruction}"

        for i in range(max_iterations):
            yield {"type": "log", "content": f"   ‚úçÔ∏è Roteirista ({self.writer_model}) - Draft {i+1}..."}
            logger.log_event("roteiro_draft", "in_progress", {"round": i+1, "model": self.writer_model})

            writer_prompt = f"""
Role: World-Class YouTube Scriptwriter.
Topic: {topic}. Chapter: {chapter_title}.
Context Data: {facts}

CRITICAL CONSTRAINTS:
1. LANGUAGE: ENGLISH ONLY. NEVER TRANSLATE.
2. FORMAT: VALID JSON ONLY.
3. DURATION: {self.duration_instruction}

Critique Feedback to fix: {feedback}

OUTPUT JSON: {{ "scenes": [ {{ "narration": "English text...", "visual_search_term": "English keyword", "visual_ai_prompt": "English prompt" }} ] }}
"""

            res_writer = await generate_text(self.writer_provider, self.writer_model, writer_prompt)
            if 'error' in res_writer:
                yield {"type": "error", "content": res_writer['error']}
                return

            # ==========================================
            # OTIMIZA√á√ÉO #3: FALLBACK PARA JSON INV√ÅLIDO
            # ==========================================
            try:
                clean_json = res_writer['text'].replace("```json","").replace("```","").strip()
                current_draft_json = json.loads(clean_json)
                script_text = " ".join([s['narration'] for s in current_draft_json.get('scenes', [])])
            except json.JSONDecodeError as json_err:
                yield {"type": "log", "content": f"   ‚ö†Ô∏è JSON inv√°lido detectado. Tentando corrigir..."}
                
                # Tenta corrigir o JSON com o pr√≥prio LLM
                fix_prompt = f"""
The following text should be valid JSON but has syntax errors. Fix it and return ONLY the corrected JSON, nothing else.

Broken JSON:
{res_writer['text']}

Return ONLY valid JSON in this exact format:
{{ "scenes": [ {{ "narration": "text", "visual_search_term": "keyword", "visual_ai_prompt": "prompt" }} ] }}
"""
                
                try:
                    res_fix = await generate_text(self.writer_provider, self.writer_model, fix_prompt)
                    if 'error' not in res_fix:
                        fixed_json = res_fix['text'].replace("```json","").replace("```","").strip()
                        current_draft_json = json.loads(fixed_json)
                        script_text = " ".join([s['narration'] for s in current_draft_json.get('scenes', [])])
                        yield {"type": "log", "content": "   ‚úÖ JSON corrigido com sucesso!"}
                    else:
                        yield {"type": "log", "content": "   ‚ö†Ô∏è Falha ao corrigir JSON. Retentando..."}
                        continue
                except:
                    yield {"type": "log", "content": "   ‚ö†Ô∏è Falha ao corrigir JSON. Retentando..."}
                    continue
            except Exception as e:
                yield {"type": "log", "content": f"   ‚ö†Ô∏è Erro inesperado ao processar JSON: {str(e)[:50]}. Retentando..."}
                continue

            yield {"type": "log", "content": f"   üßê Cr√≠tico ({self.critic_model}): Avaliando..."}

            critic_prompt = f"""
Role: Ruthless YouTube Consultant.
Script: "{script_text}"

TASK: Check retention and constraints.
CRITICAL CHECK: IS THE SCRIPT IN ENGLISH? IF NOT, SCORE 0.

Output JSON: {{ "score": (0-100), "feedback": "Fix instructions." }}
"""

            res_critic = await generate_text(self.critic_provider, self.critic_model, critic_prompt)
            if 'error' in res_critic:
                yield {"type": "error", "content": res_critic['error']}
                return

            try:
                clean_critic = res_critic['text'].replace("```json","").replace("```","").strip()
                critic_data = json.loads(clean_critic)
                score = critic_data.get('score', 50)
                feedback = critic_data.get('feedback', '')

                yield {"type": "log", "content": f"   üìä Nota: {score}/100. Feedback: {feedback[:50]}..."}
                logger.log_event("critico_resultado", "completed", {"round": i+1, "score": score})

                if score >= 90:
                    yield {"type": "log", "content": "   ‚úÖ APROVADO PELO CR√çTICO!"}
                    yield {"type": "result", "content": current_draft_json}
                    return
            except:
                # Se o cr√≠tico tamb√©m retornar JSON inv√°lido, assume score mediano
                yield {"type": "log", "content": "   ‚ö†Ô∏è Resposta do cr√≠tico inv√°lida. Assumindo score 75..."}
                score = 75
                feedback = "Continue melhorando a reten√ß√£o e estrutura viral."

        yield {"type": "log", "content": "   ‚ö†Ô∏è Usando melhor vers√£o dispon√≠vel."}
        yield {"type": "result", "content": current_draft_json}

# --- GERA√á√ÉO DE IMAGENS ---
async def generate_image_with_provider(prompt, provider, aspect_ratio, seed=None, style_template="documentary"):
    """
    Gera imagem usando o provider especificado
    
    Args:
        prompt: Descri√ß√£o da cena
        provider: flux_pro, dalle3, sdxl, banana, pollinations
        aspect_ratio: vertical ou horizontal
        seed: Seed para consist√™ncia (opcional)
        style_template: documentary, cinematic, photorealistic
    
    Returns:
        tuple: (image_path, provider_used) ou dict com error
    """
    
    # Valida provider
    if provider not in IMAGE_PROVIDERS:
        return {"error": f"Provider inv√°lido: {provider}"}
    
    config = IMAGE_PROVIDERS[provider]
    
    # Verifica API key se necess√°rio
    if config["requires_api"]:
        api_key_var = config["api_key_var"]
        if api_key_var == "OPENAI_API_KEY" and not OPENAI_API_KEY:
            return {"error": f"‚ùå ERRO CR√çTICO: {provider} selecionado mas OPENAI_API_KEY n√£o configurada. Configure no .env ou troque o provider."}
        elif api_key_var == "REPLICATE_API_KEY" and not REPLICATE_API_KEY:
            return {"error": f"‚ùå ERRO CR√çTICO: {provider} selecionado mas REPLICATE_API_KEY n√£o configurada. Configure no .env ou troque o provider."}
        
        if api_key_var == "REPLICATE_API_KEY":
            os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_KEY
    
    # Aplica template de estilo
    template = VISUAL_STYLE_TEMPLATES.get(style_template, VISUAL_STYLE_TEMPLATES["documentary"])
    enhanced_prompt = template.format(scene_description=prompt)
    
    # Determina aspect ratio
    aspect = "9:16" if aspect_ratio == "vertical" else "16:9"
    width = 720 if aspect_ratio == "vertical" else 1280
    height = 1280 if aspect_ratio == "vertical" else 720
    
    try:
        # ===== FLUX PRO =====
        if provider == "flux_pro":
            import replicate
            
            input_params = {
                "prompt": enhanced_prompt,
                "aspect_ratio": aspect,
                "output_format": "png",
                "output_quality": 100,
                "safety_tolerance": 2
            }
            
            if seed is not None and config["supports_seed"]:
                input_params["seed"] = seed
            
            output = replicate.run(
                "black-forest-labs/flux-pro",
                input=input_params
            )
            
            # Download da imagem
            # CORRE√á√ÉO: Tratamento para objeto FileOutput do Replicate
            if isinstance(output, list):
                image_url = str(output[0])
            else:
                image_url = str(output) # Converte FileOutput diretamente para URL
            
            image_data = requests.get(image_url, timeout=30).content
            
            return image_data, "Flux Pro"
        
        # ===== STABLE DIFFUSION XL =====
        elif provider == "sdxl":
            import replicate
            
            input_params = {
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "num_outputs": 1,
                "scheduler": "K_EULER",
                "num_inference_steps": 50,
                "guidance_scale": 7.5,
                "refine": "expert_ensemble_refiner"
            }
            
            if seed is not None and config["supports_seed"]:
                input_params["seed"] = seed
            
            output = replicate.run(
                "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
                input=input_params
            )
            
            image_url = output[0] if isinstance(output, list) else output
            image_data = requests.get(image_url, timeout=30).content
            
            return image_data, "SDXL"
        
        # ===== BANANA (Nano model) =====
        elif provider == "banana":
            import replicate
            
            input_params = {
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "num_outputs": 1
            }
            
            if seed is not None and config["supports_seed"]:
                input_params["seed"] = seed
            
            output = replicate.run(
                "fofr/sdxl-neon-mecha:c3c9c5f0e4ed4a8c876f15f2af7c4b5f46f12b2fd0dd69a0d54e2d0b6e3e9c0e",
                input=input_params
            )
            
            image_url = output[0] if isinstance(output, list) else output
            image_data = requests.get(image_url, timeout=30).content
            
            return image_data, "Nano Banana"
        
        # ===== DALL-E 3 =====
        elif provider == "dalle3":
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            # DALL-E 3 n√£o suporta seed ou aspect ratio custom
            size = "1024x1792" if aspect_ratio == "vertical" else "1792x1024"
            
            response = client.images.generate(
                model="dall-e-3",
                prompt=enhanced_prompt[:4000],  # DALL-E tem limite de caracteres
                size=size,
                quality="hd",
                n=1
            )
            
            image_url = response.data[0].url
            image_data = requests.get(image_url, timeout=30).content
            
            return image_data, "DALL-E 3"
        
        # ===== POLLINATIONS =====
        elif provider == "pollinations":
            url = f"https://image.pollinations.ai/prompt/{enhanced_prompt.replace(' ','%20')}?width={width}&height={height}&model=flux&nologo=true"
            
            image_data = requests.get(url, timeout=30).content
            
            return image_data, "Pollinations"
    
    except Exception as e:
        error_msg = str(e)
        
        # Detecta erros espec√≠ficos
        if "credit" in error_msg.lower() or "quota" in error_msg.lower() or "billing" in error_msg.lower():
            return {"error": f"‚ùå ERRO CR√çTICO: Cr√©ditos esgotados no {config['name']}. Adicione cr√©ditos ou troque o provider."}
        
        return {"error": f"Erro ao gerar imagem com {config['name']}: {error_msg}"}
    
    return {"error": f"Provider {provider} n√£o implementado corretamente"}
    narr_text = scene.get('narration') or scene.get('script') or scene.get('text')
    if not narr_text: return None
    
    audio_path = os.path.join(project_path, f"act{act_index}_scene{index}.mp3")
    clean_txt = clean_text_for_tts(narr_text)
    
    # Obt√©m configura√ß√µes de voz e estilo
    voice_config = VOICE_CONFIGS.get(voice_config_key, VOICE_CONFIGS["edge_tts"])
    style_config = VOICE_STYLES.get(voice_style, VOICE_STYLES["documentary"])
    
    # Adiciona instru√ß√£o de estilo ao texto (para TTS que suportam)
    styled_prompt = f"{style_config['instruction']}\n\n{clean_txt}"
    
    tts_model_used = "None"
    provider = voice_config["provider"]
    
    # ===== OPENAI TTS =====
    if provider == "openai":
        if not OPENAI_API_KEY:
            return {"error": "ERRO VOZ: OpenAI TTS selecionado mas sem chave API."}
        
        try:
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.audio.speech.create(
                model="tts-1-hd",  # ou "tts-1" para mais r√°pido
                voice=voice_config["voice"],
                input=clean_txt,
                speed=style_config["speed"]
            )
            
            response.stream_to_file(audio_path)
            tts_model_used = f"OpenAI TTS ({voice_config['voice']})"
        
        except Exception as e:
            return {"error": f"FALHA OpenAI TTS: {str(e)}"}
    
    # ===== ELEVENLABS =====
    elif provider == "elevenlabs":
        if not ELEVENLABS_API_KEY:
            return {"error": "ERRO VOZ: ElevenLabs selecionado mas sem chave API."}
        
        try:
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}"
            headers = {"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"}
            
            # ElevenLabs suporta stability e similarity_boost para controle de estilo
            data = {
                "text": clean_txt,
                "model_id": "eleven_turbo_v2",
                "voice_settings": {
                    "stability": 0.5 if voice_style == "hype" else 0.75,
                    "similarity_boost": 0.75
                }
            }
            
            r = requests.post(url, json=data, headers=headers, timeout=20)
            
            if r.status_code == 200:
                with open(audio_path, 'wb') as f: f.write(r.content)
                tts_model_used = "ElevenLabs"
            else:
                return {"error": f"ElevenLabs Error ({r.status_code}): {r.text}"}
        
        except Exception as e:
            return {"error": f"FALHA ElevenLabs: {str(e)}"}
    
    # ===== GEMINI TTS (usando Google Cloud TTS) =====
    elif provider == "gemini":
        if not GEMINI_API_KEY:
            return {"error": "ERRO VOZ: Gemini TTS selecionado mas sem chave API."}
        
        try:
            # Usa a API do Google Cloud Text-to-Speech via REST
            url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={GEMINI_API_KEY}"
            headers = {"Content-Type": "application/json"}
            
            payload = {
                "input": {"text": clean_txt},
                "voice": {
                    "languageCode": "en-US",
                    "name": voice_config["voice"],
                    "ssmlGender": "MALE"
                },
                "audioConfig": {
                    "audioEncoding": "MP3",
                    "speakingRate": style_config["speed"],
                    "pitch": float(style_config["pitch"].replace("Hz", ""))
                }
            }
            
            r = requests.post(url, json=payload, headers=headers, timeout=20)
            
            if r.status_code == 200:
                import base64
                audio_content = base64.b64decode(r.json()["audioContent"])
                with open(audio_path, 'wb') as f: f.write(audio_content)
                tts_model_used = "Gemini TTS"
            else:
                # Fallback para Edge TTS se Gemini falhar
                await edge_tts.Communicate(clean_txt, "en-US-ChristopherNeural").save(audio_path)
                tts_model_used = "EdgeTTS (Fallback)"
        
        except Exception as e:
            # Fallback para Edge TTS
            await edge_tts.Communicate(clean_txt, "en-US-ChristopherNeural").save(audio_path)
            tts_model_used = "EdgeTTS (Fallback)"
    
    # ===== EDGE TTS (Fallback padr√£o) =====
    else:
        try:
            # Edge TTS com ajuste de velocidade via SSML
            if voice_style == "hype":
                ssml_text = f'<speak><prosody rate="fast">{clean_txt}</prosody></speak>'
            elif voice_style == "asmr":
                ssml_text = f'<speak><prosody rate="slow" volume="soft">{clean_txt}</prosody></speak>'
            else:
                ssml_text = clean_txt
            
            await edge_tts.Communicate(ssml_text, voice_config["voice"]).save(audio_path)
            tts_model_used = "EdgeTTS"
        except Exception as e:
            return {"error": f"FALHA TOTAL DE VOZ: {str(e)}"}
    
# --- GERA√á√ÉO DE M√çDIA ---
async def generate_visuals_and_audio(scene, index, act_index, project_path, voice_config_key, voice_style, image_provider, project_seed, visual_style):
    narr_text = scene.get('narration') or scene.get('script') or scene.get('text')
    if not narr_text: return None
    
    audio_path = os.path.join(project_path, f"act{act_index}_scene{index}.mp3")
    clean_txt = clean_text_for_tts(narr_text)
    
    # Obt√©m configura√ß√µes de voz e estilo
    voice_config = VOICE_CONFIGS.get(voice_config_key, VOICE_CONFIGS["edge_tts"])
    style_config = VOICE_STYLES.get(voice_style, VOICE_STYLES["documentary"])
    
    # Adiciona instru√ß√£o de estilo ao texto (para TTS que suportam)
    styled_prompt = f"{style_config['instruction']}\n\n{clean_txt}"
    
    tts_model_used = "None"
    provider = voice_config["provider"]
    
    # ===== GERA√á√ÉO DE √ÅUDIO (mant√©m l√≥gica original) =====
    if provider == "openai":
        if not OPENAI_API_KEY:
            return {"error": "ERRO VOZ: OpenAI TTS selecionado mas sem chave API."}
        
        try:
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.audio.speech.create(
                model="tts-1-hd",
                voice=voice_config["voice"],
                input=clean_txt,
                speed=style_config["speed"]
            )
            
            response.stream_to_file(audio_path)
            tts_model_used = f"OpenAI TTS ({voice_config['voice']})"
        
        except Exception as e:
            return {"error": f"FALHA OpenAI TTS: {str(e)}"}
    
    elif provider == "elevenlabs":
        if not ELEVENLABS_API_KEY:
            return {"error": "ERRO VOZ: ElevenLabs selecionado mas sem chave API."}
        
        try:
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}"
            headers = {"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"}
            
            data = {
                "text": clean_txt,
                "model_id": "eleven_turbo_v2",
                "voice_settings": {
                    "stability": 0.5 if voice_style == "hype" else 0.75,
                    "similarity_boost": 0.75
                }
            }
            
            r = requests.post(url, json=data, headers=headers, timeout=20)
            
            if r.status_code == 200:
                with open(audio_path, 'wb') as f: f.write(r.content)
                tts_model_used = "ElevenLabs"
            else:
                return {"error": f"ElevenLabs Error ({r.status_code}): {r.text}"}
        
        except Exception as e:
            return {"error": f"FALHA ElevenLabs: {str(e)}"}
    
    elif provider == "gemini":
        if not GEMINI_API_KEY:
            return {"error": "ERRO VOZ: Gemini TTS selecionado mas sem chave API."}
        
        try:
            url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={GEMINI_API_KEY}"
            headers = {"Content-Type": "application/json"}
            
            payload = {
                "input": {"text": clean_txt},
                "voice": {
                    "languageCode": "en-US",
                    "name": voice_config["voice"],
                    "ssmlGender": "MALE"
                },
                "audioConfig": {
                    "audioEncoding": "MP3",
                    "speakingRate": style_config["speed"],
                    "pitch": float(style_config["pitch"].replace("Hz", ""))
                }
            }
            
            r = requests.post(url, json=payload, headers=headers, timeout=20)
            
            if r.status_code == 200:
                import base64
                audio_content = base64.b64decode(r.json()["audioContent"])
                with open(audio_path, 'wb') as f: f.write(audio_content)
                tts_model_used = "Gemini TTS"
            else:
                await edge_tts.Communicate(clean_txt, "en-US-ChristopherNeural").save(audio_path)
                tts_model_used = "EdgeTTS (Fallback)"
        
        except Exception as e:
            await edge_tts.Communicate(clean_txt, "en-US-ChristopherNeural").save(audio_path)
            tts_model_used = "EdgeTTS (Fallback)"
    
    else:
        try:
            if voice_style == "hype":
                ssml_text = f'<speak><prosody rate="fast">{clean_txt}</prosody></speak>'
            elif voice_style == "asmr":
                ssml_text = f'<speak><prosody rate="slow" volume="soft">{clean_txt}</prosody></speak>'
            else:
                ssml_text = clean_txt
            
            await edge_tts.Communicate(ssml_text, voice_config["voice"]).save(audio_path)
            tts_model_used = "EdgeTTS"
        except Exception as e:
            return {"error": f"FALHA TOTAL DE VOZ: {str(e)}"}
    
    # ===== GERA√á√ÉO DE IMAGEM (NOVO SISTEMA) =====
    search_term = scene.get('visual_search_term', 'business concept')
    ai_prompt = scene.get('visual_ai_prompt', search_term)
    media_path = os.path.join(project_path, f"act{act_index}_media{index}.png")
    
    if not os.path.exists(media_path):
        # Usa o provider selecionado pelo usu√°rio
        result = await generate_image_with_provider(
            prompt=ai_prompt,
            provider=image_provider,
            aspect_ratio="vertical" if "vertical" in project_path else "horizontal",
            seed=project_seed,
            style_template=visual_style
        )
        
        # Verifica se houve erro cr√≠tico
        if isinstance(result, dict) and "error" in result:
            return result  # Retorna erro para parar a execu√ß√£o
        
        # Salva imagem
        image_data, vis_source = result
        with open(media_path, 'wb') as f:
            f.write(image_data)
    else:
        vis_source = "Cache"

    return audio_path, media_path, tts_model_used, vis_source

# ==========================================
# OTIMIZA√á√ÉO #2: RENDERIZA√á√ÉO OTIMIZADA
# ==========================================

def render_scene_optimized(audio_path, media_path, output_path, aspect_ratio="horizontal"):
    """Renderiza√ß√£o com configura√ß√µes otimizadas para hardware modesto"""
    try:
        # Verifica se os arquivos de entrada existem
        if not os.path.exists(audio_path):
            raise Exception(f"√Åudio n√£o encontrado: {audio_path}")
        if not os.path.exists(media_path):
            raise Exception(f"Imagem n√£o encontrada: {media_path}")
        
        # Obt√©m resolu√ß√£o baseada no aspect ratio e perfil
        target_w, target_h = ASPECT_RATIOS[aspect_ratio]["resolutions"][CURRENT_PROFILE]
        
        print(f"\nüé¨ RENDERIZANDO CENA ({ASPECT_RATIOS[aspect_ratio]['name']}):")
        print(f"   √Åudio: {os.path.basename(audio_path)} ({os.path.getsize(audio_path)/1024:.1f}KB)")
        print(f"   Imagem: {os.path.basename(media_path)} ({os.path.getsize(media_path)/1024:.1f}KB)")
        
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration + 0.2
        print(f"   Dura√ß√£o √°udio: {duration:.2f}s")

        # Cria clip de imagem e verifica dimens√µes
        try:
            clip = ImageClip(media_path).set_duration(duration)
            print(f"   Imagem carregada: {clip.w}x{clip.h}")
        except Exception as img_e:
            raise Exception(f"Erro ao carregar imagem: {img_e}")

        # Crop e resize para aspect ratio escolhido
        if clip.w / clip.h > target_w / target_h:
            clip = clip.resize(height=target_h)
        else:
            clip = clip.resize(width=target_w)

        clip = clip.crop(x_center=clip.w/2, y_center=clip.h/2, width=target_w, height=target_h)
        print(f"   Resolu√ß√£o final: {target_w}x{target_h} ({ASPECT_RATIOS[aspect_ratio]['ratio']})")

        # Zoom sutil
        clip = clip.resize(lambda t: 1 + 0.04*t)

        # Legendas (se habilitadas no perfil)
        if SETTINGS['enable_subtitles']:
            try:
                sub_gen = SubtitleGenerator()
                subs = sub_gen.generate_karaoke(audio_path, target_w, target_h)
                print(f"   Legendas: {len(subs)} clips")
                final_scene = CompositeVideoClip([clip] + subs).set_audio(audio_clip)
            except Exception as e:
                print(f"‚ö†Ô∏è Erro legendas: {e}")
                final_scene = clip.set_audio(audio_clip)
        else:
            print(f"   Legendas: desabilitadas")
            final_scene = clip.set_audio(audio_clip)

        print(f"   Renderizando com preset={SETTINGS['preset']}, fps={SETTINGS['fps']}, threads={SETTINGS['threads']}...")
        
        # Renderiza√ß√£o com par√¢metros otimizados e garantidos para concatena√ß√£o
        final_scene.write_videofile(
            output_path,
            fps=SETTINGS['fps'],
            codec="libx264",
            audio_codec="aac",
            preset=SETTINGS['preset'],
            threads=SETTINGS['threads'],
            bitrate=SETTINGS['bitrate'],
            # Par√¢metros cr√≠ticos para compatibilidade universal
            ffmpeg_params=[
                "-pix_fmt", "yuv420p",  # Compatibilidade universal
                "-profile:v", "baseline",  # Mudado de 'high' para 'baseline' (m√°xima compatibilidade)
                "-level", "3.0",  # Mudado de 4.0 para 3.0 (compat√≠vel com navegadores antigos)
                "-movflags", "+faststart",  # Stream progressivo
                "-ar", "44100",
                "-ac", "2"
            ],
            logger=None,
            write_logfile=False,
            temp_audiofile=f"{output_path}_temp_audio.m4a",
            remove_temp=True
        )

        # Cleanup
        final_scene.close()
        audio_clip.close()
        clip.close()
        
        print(f"   ‚úÖ V√≠deo salvo: {os.path.getsize(output_path)/1024:.1f}KB")

        return output_path

    except Exception as e:
        raise Exception(f"Erro na renderiza√ß√£o: {str(e)}")

# --- STREAMING ---
@app.get("/create-stream")
async def create_documentary_stream(
    topic: str, 
    writer_provider: str, 
    writer_model: str, 
    critic_provider: str, 
    critic_model: str, 
    duration: str = "medium", 
    voice_config: str = "edge_tts", 
    voice_style: str = "documentary", 
    aspect_ratio: str = "horizontal",
    image_provider: str = "pollinations",
    use_consistent_seed: bool = True,
    visual_style: str = "documentary"
):
    async def event_generator():
        try:
            # Valida√ß√£o do aspect ratio
            if aspect_ratio not in ASPECT_RATIOS:
                yield f"data: {json.dumps({'status': 'error', 'message': f'Aspect ratio inv√°lido: {aspect_ratio}'})}\n\n"
                return
            
            # Valida√ß√£o do image provider
            if image_provider not in IMAGE_PROVIDERS:
                yield f"data: {json.dumps({'status': 'error', 'message': f'Image provider inv√°lido: {image_provider}'})}\n\n"
                return
            
            # Verifica se provider requer API key
            provider_config = IMAGE_PROVIDERS[image_provider]
            if provider_config["requires_api"]:
                api_key_var = provider_config["api_key_var"]
                if api_key_var == "OPENAI_API_KEY" and not OPENAI_API_KEY:
                    error_msg = f'{provider_config["name"]} requer OPENAI_API_KEY no .env'
                    yield f"data: {json.dumps({'status': 'error', 'message': error_msg})}\n\n"
                    return
                elif api_key_var == "REPLICATE_API_KEY" and not REPLICATE_API_KEY:
                    error_msg = f'{provider_config["name"]} requer REPLICATE_API_KEY no .env'
                    yield f"data: {json.dumps({'status': 'error', 'message': error_msg})}\n\n"
                    return
            
            # Gera seed √∫nico para o projeto (se consist√™ncia habilitada)
            project_seed = random.randint(1000, 99999) if use_consistent_seed else None
            
            aspect_info = ASPECT_RATIOS[aspect_ratio]
            resolution = aspect_info["resolutions"][CURRENT_PROFILE]
            
            voice_info = VOICE_CONFIGS.get(voice_config, VOICE_CONFIGS["edge_tts"])
            style_info = VOICE_STYLES.get(voice_style, VOICE_STYLES["documentary"])
            
            yield await send_log(f"üöÄ INICIANDO: {topic}")
            yield await send_log(f"üìê Formato: {aspect_info['name']} ({aspect_info['ratio']}) - {resolution[0]}x{resolution[1]}")
            yield await send_log(f"üéôÔ∏è Voz: {voice_info['name']} | Estilo: {style_info['name']}")
            yield await send_log(f"üé® Imagens: {provider_config['name']} | Seed: {project_seed if use_consistent_seed else 'Desabilitado'}")
            yield await send_log(f"üñºÔ∏è Estilo Visual: {visual_style.capitalize()}")
            yield await send_log(f"‚öôÔ∏è Perfil: {CURRENT_PROFILE}")

            pid = datetime.now().strftime("%Y%m%d_%H%M%S")
            path = os.path.join(PROJECTS_DIR, pid)
            os.makedirs(path, exist_ok=True)

            duration_map = {
                "short": {"structure": "1 ACT.", "constraint": "MAX 150 WORDS. FAST PACED.", "acts_prompt": "Output JSON: { \"acts\": [ { \"title\": \"The Story\", \"focus\": \"Hook\" } ] }"},
                "medium": {"structure": "3 Acts.", "constraint": "Standard Length (400-600 words).", "acts_prompt": "Output JSON: { \"acts\": [ { \"title\": \"Hook\", \"focus\": \"Mystery\" }, { \"title\": \"Body\", \"focus\": \"Analysis\" }, { \"title\": \"Payoff\", \"focus\": \"Conclusion\" } ] }"},
                "long": {"structure": "5 Acts.", "constraint": "Deep Dive (1500+ words).", "acts_prompt": "Output JSON: { \"acts\": [ { \"title\": \"Intro\", \"focus\": \"Hook\" }, { \"title\": \"Context\", \"focus\": \"History\" }, { \"title\": \"Conflict\", \"focus\": \"Drama\" }, { \"title\": \"Climax\", \"focus\": \"Peak\" }, { \"title\": \"Outro\", \"focus\": \"Future\" } ] }"},
                "surprise": {"structure": "AI Choice.", "constraint": "OPTIMIZE FOR RETENTION.", "acts_prompt": "Decide best structure. Output JSON: { \"acts\": [...] }"}
            }
            d_config = duration_map.get(duration, duration_map["medium"])

            writer_conf = {"provider": writer_provider, "model": writer_model}
            critic_conf = {"provider": critic_provider, "model": critic_model}
            logger = ProjectLogger(path, topic, writer_conf, critic_conf, duration, voice_config, voice_style)

            viral_brain = ViralBrain(writer_provider, writer_model, critic_provider, critic_model, d_config['constraint'])
            pdf_gen = PDFGenerator()

            yield await send_log("üïµÔ∏è Pesquisando dados...")
            with DDGS() as ddgs:
                facts = "\n".join([f"- {r['title']}: {r['body']}" for r in ddgs.text(topic, max_results=5)])

            yield await send_log("üèóÔ∏è Arquitetura Viral...")
            struct_prompt = f"Context: Viral Doc '{topic}'. Data: {facts}. {d_config['structure']} {d_config['acts_prompt']} LANGUAGE: ENGLISH ONLY."

            res = await generate_text(writer_provider, writer_model, struct_prompt)
            if 'error' in res:
                yield await send_log(f"‚ùå Erro Inicial: {res['error']}")
                yield f"data: {json.dumps({'status': 'error', 'message': res['error']})}\n\n"
                return
            try: acts = json.loads(res['text'].replace("```json","").replace("```","").strip())['acts']
            except: acts = [{"title": "Intro", "focus": "Start"}]

            generated_files = []
            full_script_data = []

            for idx, act in enumerate(acts):
                yield await send_log(f"üé¨ Ato {idx+1}: {act['title']}...")

                plan = None
                async for brain_event in viral_brain.run_writer_critic_loop(topic, act['title'], facts, logger):
                    if brain_event["type"] == "log":
                        yield await send_log(brain_event["content"])
                    elif brain_event["type"] == "result":
                        plan = brain_event["content"]
                    elif brain_event["type"] == "error":
                        yield await send_log(f"‚ùå Erro Fatal: {brain_event['content']}")
                        yield f"data: {json.dumps({'status': 'error', 'message': brain_event['content']})}\n\n"
                        return

                if not plan: continue
                full_script_data.append({"title": act['title'], "scenes": plan.get('scenes', [])})
                scenes = plan.get('scenes', [])

                for i, scene in enumerate(scenes):
                    yield await send_log(f"   üé• Cena {i+1}: Produzindo assets...")

                    result = await generate_visuals_and_audio(scene, i, idx, path, voice_config, voice_style, image_provider, project_seed, visual_style)

                    if isinstance(result, dict) and "error" in result:
                        yield await send_log(f"‚ùå Erro Assets: {result['error']}")
                        yield f"data: {json.dumps({'status': 'error', 'message': result['error']})}\n\n"
                        return
                    if not result: continue

                    audio_p, media_p, tts_u, vis_u = result
                    logger.log_event("cena_assets", "completed", {"tts": tts_u, "visual": vis_u})

                    yield await send_log(f"   ‚ö° Cena {i+1}: Renderizando ({SETTINGS['preset']}, {SETTINGS['fps']}fps)...")

                    try:
                        temp = os.path.join(path, f"scene_{idx}_{i}.mp4")
                        render_scene_optimized(audio_p, media_p, temp, aspect_ratio)  # Passa aspect_ratio
                        
                        # TESTE: Verifica se o v√≠deo foi gerado corretamente
                        if os.path.exists(temp):
                            size = os.path.getsize(temp)
                            yield await send_log(f"   üìπ Arquivo gerado: {size/1024:.1f}KB")
                            
                            # Testa com ffprobe (timeout maior para arquivos grandes)
                            try:
                                probe_cmd = ["ffprobe", "-v", "error", "-select_streams", "v:0",
                                           "-show_entries", "stream=codec_name,width,height", 
                                           "-of", "json", temp]
                                result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
                                info = json.loads(result.stdout)
                                if info.get('streams'):
                                    stream = info['streams'][0]
                                    yield await send_log(f"   üé• Codec: {stream.get('codec_name')}, Resolu√ß√£o: {stream.get('width')}x{stream.get('height')}")
                                else:
                                    yield await send_log(f"   ‚ö†Ô∏è AVISO: V√≠deo sem stream de v√≠deo!")
                            except subprocess.TimeoutExpired:
                                yield await send_log(f"   ‚è±Ô∏è Verifica√ß√£o demorada, mas arquivo existe")
                            except Exception as probe_e:
                                yield await send_log(f"   ‚ö†Ô∏è Verifica√ß√£o ignorada: {str(probe_e)[:50]}")
                        
                        generated_files.append(temp)
                        yield await send_log(f"   ‚úÖ Cena {i+1}: Completa!")
                    except Exception as e:
                        yield await send_log(f"‚ö†Ô∏è Erro render cena {i+1}: {e}")

            if full_script_data:
                try: pdf_gen.save_script(path, topic, full_script_data)
                except: pass

            if generated_files:
                yield await send_log(f"üßµ Costurando {len(generated_files)} cenas...")
                output_name = "final_viral.mp4"
                output_path = os.path.join(path, output_name)
                
                success = stitch_video_files(generated_files, output_path)
                
                if success and os.path.exists(output_path) and os.path.getsize(output_path) > 1000:
                    # P√≥s-processamento: Garante compatibilidade total
                    yield await send_log("üîß Otimizando compatibilidade do v√≠deo...")
                    temp_output = output_path.replace(".mp4", "_temp.mp4")
                    
                    try:
                        # Re-encode com par√¢metros de m√°xima compatibilidade
                        compat_cmd = [
                            "ffmpeg", "-y", "-i", output_path,
                            "-c:v", "libx264",
                            "-preset", "fast",
                            "-crf", "23",
                            "-pix_fmt", "yuv420p",
                            "-profile:v", "baseline",
                            "-level", "3.0",
                            "-movflags", "+faststart",
                            "-c:a", "aac",
                            "-b:a", "128k",
                            "-ar", "44100",
                            "-ac", "2",
                            temp_output
                        ]
                        
                        subprocess.run(compat_cmd, check=True, capture_output=True, text=True)
                        
                        # Substitui o arquivo original
                        os.remove(output_path)
                        os.rename(temp_output, output_path)
                        
                        yield await send_log("‚úÖ V√≠deo otimizado para navegadores!")
                    except Exception as e:
                        yield await send_log(f"‚ö†Ô∏è Otimiza√ß√£o ignorada: {str(e)}")
                        if os.path.exists(temp_output):
                            os.remove(temp_output)
                    
                    # Valida√ß√£o final
                    final_size = os.path.getsize(output_path)
                    yield await send_log(f"üìä Tamanho final: {final_size/1024/1024:.2f}MB")
                    
                    full_url = f"http://localhost:8000/projects/{pid}/{output_name}"
                    logger.finish("completed")
                    
                    yield await send_log("üéâ V√çDEO FINALIZADO!")
                    yield await send_log(f"üîó URL: {full_url}")
                    yield await send_log(f"üìÅ Pasta: projects/{pid}/")
                    
                    # Retorna JSON final com informa√ß√µes completas
                    yield f"data: {json.dumps({
                        'status': 'done', 
                        'url': full_url,
                        'project_id': pid,
                        'filename': output_name,
                        'size_mb': round(final_size / (1024*1024), 2),
                        'direct_path': f'/projects/{pid}/{output_name}'
                    })}\n\n"
                else:
                    logger.finish("failed", "Falha ao concatenar v√≠deos")
                    yield await send_log("‚ùå Erro ao unir v√≠deos")
                    yield f"data: {json.dumps({'status': 'error', 'message': 'Falha na concatena√ß√£o'})}\n\n"
            else:
                logger.finish("failed")
                yield f"data: {json.dumps({'status': 'error', 'message': 'Nenhum clipe gerado'})}\n\n"

        except Exception as e:
            yield await send_log(f"‚ùå Erro Fatal: {str(e)}")
            yield f"data: {json.dumps({'status': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.get("/available-models")
def get_available_models():
    models = {"gemini": [], "openai": []}
    if GEMINI_API_KEY:
        try:
            data = requests.get(f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}", timeout=5).json()
            if 'error' not in data:
                blacklist = ["tts", "audio", "embedding", "aqa", "vision-only"]
                for m in data.get('models', []):
                    if 'generateContent' in m.get('supportedGenerationMethods', []) and not any(b in m['name'].lower() for b in blacklist):
                        models["gemini"].append({"id": m['name'], "name": m['name'].replace("models/", "")})
                models["gemini"].sort(key=lambda x: x['name'], reverse=True)
        except: pass
    if OPENAI_API_KEY:
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            for m in client.models.list().data:
                if m.id.startswith(("gpt-", "o1-")):
                    models["openai"].append({"id": m.id, "name": m.id})
            models["openai"].sort(key=lambda x: x['name'], reverse=True)
        except: pass
    return models

@app.get("/available-voices")
def get_available_voices():
    """Retorna vozes e estilos dispon√≠veis"""
    voices = []
    
    # Adiciona vozes dispon√≠veis baseado nas chaves API
    for key, config in VOICE_CONFIGS.items():
        # Verifica se a API necess√°ria est√° dispon√≠vel
        available = True
        if config["provider"] == "openai" and not OPENAI_API_KEY:
            available = False
        elif config["provider"] == "elevenlabs" and not ELEVENLABS_API_KEY:
            available = False
        elif config["provider"] == "gemini" and not GEMINI_API_KEY:
            available = False
        
        voices.append({
            "id": key,
            "name": config["name"],
            "provider": config["provider"],
            "description": config["description"],
            "available": available
        })
    
    # Retorna vozes e estilos
    styles = []
    for key, info in VOICE_STYLES.items():
        styles.append({
            "id": key,
            "name": info["name"],
            "description": info["instruction"][:80] + "..."
        })
    
    return {
        "voices": voices,
        "styles": styles
    }

@app.get("/available-image-providers")
def get_available_image_providers():
    """Retorna providers de imagem dispon√≠veis"""
    providers = []
    
    for key, config in IMAGE_PROVIDERS.items():
        available = True
        api_status = "N√£o requer API"
        
        if config["requires_api"]:
            api_key_var = config["api_key_var"]
            if api_key_var == "OPENAI_API_KEY":
                available = bool(OPENAI_API_KEY)
                api_status = "‚úÖ Configurado" if available else "‚ùå Faltando OPENAI_API_KEY"
            elif api_key_var == "REPLICATE_API_KEY":
                available = bool(REPLICATE_API_KEY)
                api_status = "‚úÖ Configurado" if available else "‚ùå Faltando REPLICATE_API_KEY"
        
        providers.append({
            "id": key,
            "name": config["name"],
            "quality": config["quality"],
            "cost": config["cost"],
            "supports_seed": config["supports_seed"],
            "supports_aspect_ratio": config["supports_aspect_ratio"],
            "available": available,
            "api_status": api_status
        })
    
    return {
        "providers": providers,
        "visual_styles": [
            {"id": "documentary", "name": "Documentary", "description": "National Geographic quality, professional"},
            {"id": "cinematic", "name": "Cinematic", "description": "Hollywood blockbuster style, dramatic"},
            {"id": "photorealistic", "name": "Photorealistic", "description": "Ultra-realistic DSLR photography"}
        ]
    }

@app.get("/test-video/{project_id}")
def test_video(project_id: str):
    """Endpoint de teste para verificar v√≠deo"""
    video_path = os.path.join(PROJECTS_DIR, project_id, "final_viral.mp4")
    
    if not os.path.exists(video_path):
        return {"error": "V√≠deo n√£o encontrado", "path": video_path}
    
    # Diagn√≥stico completo do v√≠deo
    try:
        # Info b√°sica
        size = os.path.getsize(video_path)
        
        # FFprobe detalhado
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "stream=codec_name,width,height,r_frame_rate,duration:format=duration,bit_rate",
            "-of", "json",
            video_path
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=10)
        info = json.loads(result.stdout)
        
        # Extrai informa√ß√µes
        video_stream = next((s for s in info.get('streams', []) if s.get('codec_name') == 'h264'), None)
        audio_stream = next((s for s in info.get('streams', []) if s.get('codec_name') == 'aac'), None)
        
        diagnosis = {
            "file": {
                "path": video_path,
                "size_mb": round(size / (1024*1024), 2),
                "exists": True
            },
            "video_stream": {
                "codec": video_stream.get('codec_name') if video_stream else None,
                "resolution": f"{video_stream.get('width')}x{video_stream.get('height')}" if video_stream else None,
                "fps": video_stream.get('r_frame_rate') if video_stream else None,
                "duration": video_stream.get('duration') if video_stream else None
            } if video_stream else {"error": "Sem stream de v√≠deo!"},
            "audio_stream": {
                "codec": audio_stream.get('codec_name') if audio_stream else None,
                "duration": audio_stream.get('duration') if audio_stream else None
            } if audio_stream else {"error": "Sem stream de √°udio!"},
            "format": {
                "duration": info.get('format', {}).get('duration'),
                "bitrate": info.get('format', {}).get('bit_rate')
            },
            "url": f"http://localhost:8000/projects/{project_id}/final_viral.mp4"
        }
        
        return diagnosis
        
    except Exception as e:
        return {"error": str(e), "path": video_path}

@app.get("/player/{project_id}")
def video_player(project_id: str):
    """Player HTML5 de teste"""
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Test Player - {project_id}</title>
        <style>
            body {{
                margin: 0;
                padding: 20px;
                background: #000;
                font-family: Arial, sans-serif;
                color: #fff;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
            }}
            video {{
                width: 100%;
                max-width: 800px;
                display: block;
                margin: 20px auto;
                background: #000;
            }}
            .info {{
                background: #222;
                padding: 15px;
                border-radius: 8px;
                margin: 20px 0;
            }}
            .success {{ color: #0f0; }}
            .error {{ color: #f00; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üé¨ Video Test Player</h1>
            <div class="info">
                <p><strong>Project ID:</strong> {project_id}</p>
                <p><strong>Video URL:</strong> <a href="/projects/{project_id}/final_viral.mp4" target="_blank">/projects/{project_id}/final_viral.mp4</a></p>
            </div>
            
            <video id="player" controls autoplay>
                <source src="/projects/{project_id}/final_viral.mp4" type="video/mp4">
                Seu navegador n√£o suporta v√≠deo HTML5.
            </video>
            
            <div class="info" id="status">
                <p>‚è≥ Carregando v√≠deo...</p>
            </div>
        </div>
        
        <script>
            const video = document.getElementById('player');
            const status = document.getElementById('status');
            
            video.addEventListener('loadedmetadata', () => {{
                status.innerHTML = `
                    <p class="success">‚úÖ V√≠deo carregado com sucesso!</p>
                    <p>Dura√ß√£o: ${{video.duration.toFixed(2)}}s</p>
                    <p>Dimens√µes: ${{video.videoWidth}}x${{video.videoHeight}}</p>
                `;
            }});
            
            video.addEventListener('error', (e) => {{
                status.innerHTML = `
                    <p class="error">‚ùå Erro ao carregar v√≠deo!</p>
                    <p>Erro: ${{video.error ? video.error.message : 'Desconhecido'}}</p>
                    <p>Code: ${{video.error ? video.error.code : 'N/A'}}</p>
                `;
            }});
            
            video.addEventListener('canplay', () => {{
                console.log('‚úÖ V√≠deo pronto para reprodu√ß√£o');
            }});
        </script>
    </body>
    </html>
    """